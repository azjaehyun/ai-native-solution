# **LLM 애플리케이션 점검 리스트**

## **1. 모델 점검**

### **주요 점검 항목**
- **프롬프트 인젝션**: 악의적인 입력으로 모델이 비정상적인 동작을 수행하는지 확인.
- **민감 정보 노출**: 모델이 학습 데이터나 응답에서 민감 정보를 노출하는지 점검.
- **모델 내부 악성 페이로드**: 학습 데이터나 템플릿에 악성 코드가 포함되어 있는지 확인.
- **학습 데이터 오염**: 백도어 또는 편향된 데이터를 통해 모델 출력이 왜곡되는지 점검.

### **대응 방안**
- **프롬프트 엔지니어링**: 사용자와 시스템 프롬프트를 명확히 분리하고, 모델 역할을 고정.
- **입력 검증 및 필터링**: 금지된 키워드나 민감 정보가 포함되지 않도록 필터링.
- **모델 미세 조정**: 공격 패턴을 인식하고 안전한 응답을 생성하도록 조정.

---

## **2. LLM 통합 점검**

### **주요 점검 항목**
- **클라이언트 내 프롬프트 생성**: 프롬프트 생성 과정에서 취약점 여부 확인.
- **오류 메시지 출력**: 오류 메시지가 민감 정보를 포함하지 않도록 점검.
- **취약한 서드파티 소프트웨어 사용**: 외부 라이브러리의 보안성을 검토.
- **RAG 데이터 오염**: 벡터 DB에 악성 데이터를 삽입하여 모델 동작을 왜곡할 가능성 확인.

### **대응 방안**
- **RAG 모듈 보안 강화**: 벡터 DB 접근 권한 설정 및 데이터 검증 절차 추가.
- **오류 메시지 관리**: 디버깅 정보가 외부에 노출되지 않도록 제한.
- **서드파티 소프트웨어 검증**: 최신 보안 업데이트 적용 및 신뢰할 수 있는 라이브러리만 사용.

---

## **3. 에이전트 점검**

### **주요 점검 항목**
- **API 매개 변수 변조**: API 요청이 조작될 가능성을 점검.
- **부적절한 권한 사용**: 권한 초과로 비인가된 기능 실행 여부 확인.
- **사용자 동의 절차 누락**: 시스템 변경 작업 시 사용자 승인 절차가 구현되었는지 확인.
- **샌드박스 미적용**: 코드 실행 환경에서 격리가 이루어지는지 확인.

### **대응 방안**
- **샌드박스 적용**: 코드 실행 환경을 격리하여 시스템 자원을 보호.
- **API 보안 강화**: 매개 변수 유효성 검증 및 인증 절차 강화.
- **사용자 동의 절차 도입**: 민감 작업 수행 전 사용자 확인 프로세스 추가.

---

## **4. 위험도 평가 및 대응 전략**

각 항목은 위험도를 상(높음), 중(보통), 하(낮음)으로 평가하며, 이에 따른 우선순위를 설정합니다:

- **위험도 "상"**: 프롬프트 인젝션, 취약한 서드파티 소프트웨어 사용 등.
- **위험도 "중"**: RAG 데이터 오염, API 매개 변수 변조 등.
- **위험도 "하"**: 사용자 동의 절차 누락, 오류 메시지 출력 등.

### **종합 대응 방안**
1. **침투 테스트**: 정기적으로 보안 취약점을 시험하여 대응책 마련.
2. **모니터링 및 이상 탐지**: 실시간 로그 분석으로 이상 행동 감지.
3. **보안 정책 수립**: LLM 운영 환경에 맞는 맞춤형 보안 정책 설계.

---